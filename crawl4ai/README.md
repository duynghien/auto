# ğŸ•·ï¸ Crawl4AI Self-Hosted Stack

[English](#english) | [Tiáº¿ng Viá»‡t](#tiáº¿ng-viá»‡t)

---

## English

**Self-hosted [Crawl4AI v0.8.0](https://github.com/unclecode/crawl4ai)** â€” the most-starred open-source LLM-friendly web crawler on GitHub.  
Automated setup for **macOS (Apple Silicon + OrbStack)** and **Raspberry Pi (ARM64)**.

### âœ¨ Features

| Feature | Description |
|---|---|
| ğŸ•·ï¸ **Smart Crawling** | Async browser pool, caching, session management, proxy support |
| ğŸ“ **LLM-Ready Output** | Clean Markdown with headings, tables, code, citations |
| ğŸ¤– **AI Extraction** | LLM-powered structured data extraction (all providers via LiteLLM) |
| ğŸ“Š **Dashboard** | Real-time monitoring with system metrics & browser pool visibility |
| ğŸ® **Playground** | Interactive web UI to test & generate crawl code |
| ğŸ”Œ **MCP Server** | 7 built-in tools for AI Agents â€” supports **SSE**, **Streamable HTTP**, **WebSocket** |
| ğŸ“¸ **Media** | Screenshots, PDF export, image/video extraction |
| ğŸ”„ **Deep Crawl** | BFS/DFS/Best-First with crash recovery & resume |
| âš¡ **Prefetch Mode** | 5-10x faster URL discovery |
| ğŸª **Hooks API** | 8 hook points for custom crawling pipeline |
| ğŸ“¡ **Webhooks** | Job queue with webhook notifications |
| ğŸŒŠ **WebSocket** | Real-time streaming results |
| ğŸ“ˆ **Prometheus** | Metrics endpoint for monitoring |
| ğŸ”’ **Security** | JWT auth, rate limiting, bot detection evasion |

---

### ğŸ¤– MCP Server

#### Tools (7 built-in)

| Tool | Description |
|---|---|
| `md` | Convert any URL to clean, LLM-ready Markdown (supports raw/fit/bm25/llm filters) |
| `html` | Extract preprocessed, sanitized HTML for schema building |
| `screenshot` | Capture full-page PNG screenshots of any URL |
| `pdf` | Generate PDF documents from web pages |
| `execute_js` | Run JavaScript snippets on pages and get results |
| `crawl` | Multi-URL batch crawling with browser/crawler configs |
| `ask` | Query Crawl4AI library docs/code for AI assistant context |

#### Transport Protocols

The MCP server supports **3 transport protocols** for maximum compatibility with different AI agents:

| Protocol | Endpoint | Best For |
|---|---|---|
| **SSE** (Server-Sent Events) | `/mcp/sse` | Claude Desktop, Claude Code, Antigravity, most MCP clients |
| **Streamable HTTP** | `/mcp/streamable` | LobeHub, agents requiring POST-based JSON-RPC |
| **WebSocket** | `/mcp/ws` | Real-time bidirectional communication |

Additional endpoints:
- **Schema**: `/mcp/schema` â€” JSON schema of all available tools

#### AI Agent Integration

<details>
<summary><b>ğŸŸ£ Claude Desktop</b></summary>

Add to `~/.claude/claude_desktop_config.json`:
```json
{
  "mcpServers": {
    "crawl4ai": {
      "transport": "sse",
      "url": "http://localhost:11235/mcp/sse"
    }
  }
}
```
</details>

<details>
<summary><b>ğŸŸ£ Claude Code (CLI)</b></summary>

```bash
claude mcp add --transport sse crawl4ai http://localhost:11235/mcp/sse
```
</details>

<details>
<summary><b>ğŸ”µ LobeHub</b></summary>

1. Go to **Settings â†’ MCP Plugins â†’ Add Custom Plugin**
2. Set **Transport**: `Streamable HTTP`
3. Set **URL**: `http://<your-ip>:11235/mcp/streamable`
4. Save â€” all 7 tools will be discovered automatically
</details>

<details>
<summary><b>ğŸŸ¢ Antigravity</b></summary>

Add to `.agent/mcp.json`:
```json
{
  "mcpServers": {
    "crawl4ai": {
      "transport": "sse",
      "url": "http://localhost:11235/mcp/sse"
    }
  }
}
```
</details>

<details>
<summary><b>ğŸ”´ OpenClaw / n8n</b></summary>

Use SSE transport:
- **URL**: `http://<your-ip>:11235/mcp/sse`
- **Transport**: SSE
</details>

<details>
<summary><b>ğŸŸ¡ Other MCP Clients</b></summary>

Any MCP-compatible client can connect via:
- **SSE**: `http://<host>:11235/mcp/sse` (most common)
- **Streamable HTTP**: `http://<host>:11235/mcp/streamable` (POST JSON-RPC)
- **WebSocket**: `ws://<host>:11235/mcp/ws`
</details>

---

### ğŸ“‹ Requirements

| Platform | Requirements |
|---|---|
| **macOS** | Apple Silicon (M1/M2/M3/M4) + [OrbStack](https://orbstack.dev/) or Docker Desktop |
| **Raspberry Pi** | Pi 4 (4GB+) or Pi 5 + Raspberry Pi OS 64-bit |

### ğŸ› ï¸ Installation

```bash
# Clone the repository
mkdir -p ~/self-hosted
cd ~/self-hosted
git clone https://github.com/duynghien/auto.git
cd auto/crawl4ai

# macOS
chmod +x setup.sh c4ai.sh
./setup.sh

# Raspberry Pi
sudo chmod +x install-pi.sh c4ai.sh
sudo ./install-pi.sh
```

The setup script will:
1. Check prerequisites (Docker, architecture)
2. Let you choose between **Pull Image** (recommended) or **Build from Source**
3. Configure LLM API keys (optional â€” can add later)
4. Deploy the container with all features
5. Run health checks and show all endpoints

### ğŸ—ºï¸ All Endpoints

| Endpoint | URL |
|---|---|
| API | `http://localhost:11235` |
| Dashboard | `http://localhost:11235/dashboard` |
| Playground | `http://localhost:11235/playground` |
| Health | `http://localhost:11235/health` |
| Metrics | `http://localhost:11235/metrics` |
| MCP SSE | `http://localhost:11235/mcp/sse` |
| MCP Streamable HTTP | `http://localhost:11235/mcp/streamable` |
| MCP WebSocket | `ws://localhost:11235/mcp/ws` |
| MCP Schema | `http://localhost:11235/mcp/schema` |

### ğŸ“¦ Management

```bash
./c4ai.sh start     # Start Crawl4AI
./c4ai.sh stop      # Stop Crawl4AI
./c4ai.sh restart   # Restart Crawl4AI
./c4ai.sh status    # Container status + health check
./c4ai.sh logs      # Follow container logs
./c4ai.sh update    # Pull latest image & restart
./c4ai.sh test      # Run health/feature tests
./c4ai.sh info      # Show all endpoints & MCP tools
./c4ai.sh shell     # Open shell in container
```

### âš™ï¸ Configuration

| File | Purpose |
|---|---|
| `.env` | Docker Compose settings â€” created from `.env.example` (port, memory, build type) |
| `.llm.env` | LLM API keys â€” created from `.llm.env.example` (gitignored) |
| `config.yml` | Server config (security, rate limit, logging, browser pool) |
| `docker-entrypoint.sh` | Auto-patches on startup (LLM provider, MCP transport) |

#### LLM Configuration

Edit `.llm.env` to configure your LLM provider:

```bash
# Use OpenAI
LLM_PROVIDER=openai/gpt-4o-mini
OPENAI_API_KEY=sk-...

# Use Anthropic
LLM_PROVIDER=anthropic/claude-3-haiku
ANTHROPIC_API_KEY=sk-ant-...

# Use self-hosted (Ollama, vLLM, CLIProxy)
LLM_PROVIDER=openai/your-model
OPENAI_API_BASE=http://host.docker.internal:8317/v1
OPENAI_API_KEY=your-key
```

After editing, restart the container:
```bash
./c4ai.sh restart
```

### ğŸ“ Project Structure

```
crawl4ai/
â”œâ”€â”€ setup.sh                # macOS setup script
â”œâ”€â”€ install-pi.sh           # Raspberry Pi setup script
â”œâ”€â”€ c4ai.sh                 # Management helper
â”œâ”€â”€ docker-compose.yml      # Docker Compose config
â”œâ”€â”€ docker-entrypoint.sh    # Auto-patch entrypoint (LLM + MCP)
â”œâ”€â”€ config.yml              # Server configuration
â”œâ”€â”€ .env.example            # Docker Compose variables template
â”œâ”€â”€ .llm.env.example        # LLM API keys template
â””â”€â”€ .gitignore              # Ignores .env, .llm.env, debug files
```

---

## Tiáº¿ng Viá»‡t

Bá»™ cÃ i Ä‘áº·t tá»± Ä‘á»™ng **[Crawl4AI v0.8.0](https://github.com/unclecode/crawl4ai)** â€” trÃ¬nh thu tháº­p dá»¯ liá»‡u web mÃ£ nguá»“n má»Ÿ cho LLM, Ä‘Æ°á»£c star nhiá»u nháº¥t trÃªn GitHub.  
Há»— trá»£ **macOS (Apple Silicon + OrbStack)** vÃ  **Raspberry Pi (ARM64)**.

### âœ¨ TÃ­nh nÄƒng

| TÃ­nh nÄƒng | MÃ´ táº£ |
|---|---|
| ğŸ•·ï¸ **Thu tháº­p thÃ´ng minh** | Browser pool báº¥t Ä‘á»“ng bá»™, cache, quáº£n lÃ½ session, proxy |
| ğŸ“ **Äáº§u ra cho LLM** | Markdown sáº¡ch vá»›i tiÃªu Ä‘á», báº£ng, code, trÃ­ch dáº«n |
| ğŸ¤– **TrÃ­ch xuáº¥t AI** | DÃ¹ng LLM Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (há»— trá»£ táº¥t cáº£ providers) |
| ğŸ“Š **Báº£ng Ä‘iá»u khiá»ƒn** | GiÃ¡m sÃ¡t realtime vá»›i metrics há»‡ thá»‘ng & browser pool |
| ğŸ® **Playground** | Giao diá»‡n web test & táº¡o code crawl |
| ğŸ”Œ **MCP Server** | 7 tools cho AI Agent â€” há»— trá»£ SSE, Streamable HTTP, WebSocket |
| ğŸ“¸ **Media** | Chá»¥p áº£nh, xuáº¥t PDF, trÃ­ch xuáº¥t hÃ¬nh áº£nh/video |
| ğŸ”„ **Deep Crawl** | BFS/DFS/Best-First vá»›i khÃ´i phá»¥c & tiáº¿p tá»¥c khi crash |
| âš¡ **Cháº¿ Ä‘á»™ Prefetch** | KhÃ¡m phÃ¡ URL nhanh hÆ¡n 5-10 láº§n |

### ï¿½ MCP Server

#### Giao thá»©c káº¿t ná»‘i

| Giao thá»©c | Endpoint | DÃ¹ng cho |
|---|---|---|
| **SSE** | `/mcp/sse` | Claude Desktop, Claude Code, Antigravity |
| **Streamable HTTP** | `/mcp/streamable` | LobeHub (dÃ¹ng POST JSON-RPC) |
| **WebSocket** | `/mcp/ws` | Giao tiáº¿p hai chiá»u realtime |

#### Káº¿t ná»‘i AI Agent

```bash
# Claude Desktop/Code
claude mcp add --transport sse crawl4ai http://localhost:11235/mcp/sse

# LobeHub â†’ Settings â†’ MCP Plugins
# Transport: Streamable HTTP
# URL: http://<ip>:11235/mcp/streamable

# Antigravity / OpenClaw
# SSE URL: http://localhost:11235/mcp/sse
```

### ğŸ› ï¸ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t

```bash
# Táº£i mÃ£ nguá»“n
mkdir -p ~/self-hosted
cd ~/self-hosted
git clone https://github.com/duynghien/auto.git
cd auto/crawl4ai

# macOS
chmod +x setup.sh c4ai.sh
./setup.sh

# Raspberry Pi
sudo chmod +x install-pi.sh c4ai.sh
sudo ./install-pi.sh
```

### ğŸ“¦ Quáº£n lÃ½

```bash
./c4ai.sh start     # Khá»Ÿi Ä‘á»™ng
./c4ai.sh stop      # Dá»«ng
./c4ai.sh restart   # Khá»Ÿi Ä‘á»™ng láº¡i
./c4ai.sh logs      # Xem logs
./c4ai.sh test      # Kiá»ƒm tra sá»©c khá»e
./c4ai.sh info      # Hiá»‡n táº¥t cáº£ endpoints + MCP tools
./c4ai.sh update    # Cáº­p nháº­t phiÃªn báº£n má»›i
```

### âš™ï¸ Cáº¥u hÃ¬nh

| File | Chá»©c nÄƒng |
|---|---|
| `.env` | CÃ i Ä‘áº·t Docker Compose â€” táº¡o tá»« `.env.example` (port, bá»™ nhá»›, kiá»ƒu build) |
| `.llm.env` | API keys cho LLM â€” táº¡o tá»« `.llm.env.example` (gitignored) |
| `config.yml` | Cáº¥u hÃ¬nh server (báº£o máº­t, giá»›i háº¡n, logging) |
| `docker-entrypoint.sh` | Tá»± Ä‘á»™ng patch khi khá»Ÿi Ä‘á»™ng (LLM provider, MCP transport) |

---

## ğŸ¤ Support & Community

- **Website**: [vnrom.net](https://vnrom.net)
- **Author**: [duynghien](https://github.com/duynghien)
- **Crawl4AI**: [github.com/unclecode/crawl4ai](https://github.com/unclecode/crawl4ai)

## ğŸ“„ License

This setup automation is provided as-is under the MIT License.  
Crawl4AI itself is licensed under [Apache 2.0](https://github.com/unclecode/crawl4ai/blob/main/LICENSE).
