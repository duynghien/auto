# ============================================
# Crawl4AI - LLM API Keys Configuration
# ============================================
# Copy this file to .llm.env and fill in your API keys.
# Only fill in the providers you plan to use.
#
# Usage: cp .llm.env.example .llm.env

# --- OpenAI ---
OPENAI_API_KEY=
# OPENAI_TEMPERATURE=0.7
# OPENAI_BASE_URL=https://api.openai.com/v1

# --- Anthropic ---
ANTHROPIC_API_KEY=
# ANTHROPIC_TEMPERATURE=0.7

# --- DeepSeek ---
DEEPSEEK_API_KEY=

# --- Google Gemini ---
GEMINI_API_TOKEN=

# --- Groq ---
GROQ_API_KEY=

# --- Together AI ---
TOGETHER_API_KEY=

# --- Mistral ---
MISTRAL_API_KEY=

# --- Global LLM Settings (Optional) ---
# These apply to ALL providers as defaults.
# Per-request parameters override these, and provider-specific
# env vars (e.g., OPENAI_TEMPERATURE) override globals.
#
# LLM_PROVIDER=openai/gpt-4o-mini
# LLM_TEMPERATURE=0.7
# LLM_BASE_URL=https://api.custom-proxy.com/v1

# --- Custom/Self-hosted LLM (e.g., Ollama, vLLM) ---
# LLM_PROVIDER=ollama/qwen2
# LLM_BASE_URL=http://host.docker.internal:11434
